# pyspark
In this branch we will use some Jupiter Notebooks to exercise with PySpark.

There are three folders:
1. ***docker***: contains the docker compose file. It will create a container with PySpark and Jupyter.
2. ***Notebooks***: contains the notebooks with the exercise
3. ***CSV***: contains the data to perform the exercises.

Exercise Jupiter notebook on Pyspark.

1. `docker-compose  -f docker/spark-docker-compose.yml up -d` to start the jupyter-spark container
2. Upload on Jupyter the notebooks and the CSV to start the exercises.
